spring.application.name=Analytics
spring.profiles.active=${SPRING_PROFILES_ACTIVE:local}

# Base de datos H2 deshabilitada. Usar la configuracion MySQL.
# spring.datasource.url=${SPRING_DATASOURCE_URL:jdbc:h2:mem:analytics;DB_CLOSE_DELAY=-1;MODE=MySQL}
# spring.datasource.driver-class-name=${SPRING_DATASOURCE_DRIVER_CLASS_NAME:org.h2.Driver}
# spring.datasource.username=${SPRING_DATASOURCE_USERNAME:sa}
# spring.datasource.password=${SPRING_DATASOURCE_PASSWORD:}

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=false

spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${SPRING_DATASOURCE_USERNAME}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}

spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP:localhost:9092}
spring.kafka.consumer.group-id=analitica-ms
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true

# --- Force SASL on the AdminClient (used at startup) ---
spring.kafka.admin.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.admin.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.admin.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Producer ---
spring.kafka.producer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.producer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.producer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Consumer ---
spring.kafka.consumer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.consumer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.consumer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

spring.kafka.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

analitica.kafka.inventario.topic=inventario
analitica.kafka.inventario.concurrency=1
analitica.kafka.ventas.topic=ventas
analitica.kafka.ventas.concurrency=1
analitica.kafka.dlq.enabled=false
analitica.kafka.dlq.topicSuffix=dlq
analitica.ack.enabled=true
analitica.ack.url=http://localhost:8080/events/ack

analytics.kafka.enabled=true
analytics.ack.enabled=true
analytics.ack.auth.enabled=true
analytics.ack.retry.cron=0 */1 * * * *

communication.intermediary.url=${CORE_API_URL:http://localhost:8090}

keycloak.token.url=${KEYCLOAK_TOKEN_URL:http://localhost:8080/realms/ecommerce/protocol/openid-connect/token}
keycloak.client-id=analytics-app
keycloak.client-secret=${KEYCLOAK_CLIENT_SECRET}

http.client.connect-timeout-ms=5000
http.client.read-timeout-ms=10000

management.endpoints.web.exposure.include=health,info,metrics,prometheus

server.port=${SERVER_PORT:8085}
server.servlet.context-path=/api
server.forward-headers-strategy=framework

logging.level.org.springframework.kafka=WARN
logging.level.ar.edu.uade.analytics.kafka=WARN
logging.level.ar.edu.uade.analytics.messaging=WARN
logging.level.org.hibernate.SQL=WARN
logging.level.org.hibernate.orm.jdbc.bind=WARN

spring.application.name=Analytics
spring.profiles.active=${SPRING_PROFILES_ACTIVE:local}

# Base de datos H2 deshabilitada. Usar la configuracion MySQL.
# spring.datasource.url=${SPRING_DATASOURCE_URL:jdbc:h2:mem:analytics;DB_CLOSE_DELAY=-1;MODE=MySQL}
# spring.datasource.driver-class-name=${SPRING_DATASOURCE_DRIVER_CLASS_NAME:org.h2.Driver}
# spring.datasource.username=${SPRING_DATASOURCE_USERNAME:sa}
# spring.datasource.password=${SPRING_DATASOURCE_PASSWORD:}

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=false

spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${SPRING_DATASOURCE_USERNAME}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}

spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP:localhost:9092}
spring.kafka.consumer.group-id=analitica-ms
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true

# --- Force SASL on the AdminClient (used at startup) ---
spring.kafka.admin.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.admin.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.admin.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Producer ---
spring.kafka.producer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.producer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.producer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Consumer ---
spring.kafka.consumer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.consumer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.consumer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

spring.kafka.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

#Variables para chatbot
google.api.key=${GOOGLE_API_KEY]
gemini.api.key=${GOOGLE_API_KEY}

analitica.kafka.inventario.topic=inventario
analitica.kafka.inventario.concurrency=1
analitica.kafka.ventas.topic=ventas
analitica.kafka.ventas.concurrency=1
analitica.kafka.dlq.enabled=false
analitica.kafka.dlq.topicSuffix=dlq
analitica.ack.enabled=true
analitica.ack.url=http://localhost:8080/events/ack

analytics.kafka.enabled=true
analytics.ack.enabled=true
analytics.ack.auth.enabled=true
analytics.ack.retry.cron=0 */1 * * * *

communication.intermediary.url=${KAFKA_MIDDLEWARE_URL:http://localhost:8090}

keycloak.token.url=${KEYCLOAK_TOKEN_URL:http://localhost:8080/realms/ecommerce/protocol/openid-connect/token}
keycloak.client-id=analytics-app
keycloak.client-secret=${KEYCLOAK_CLIENT_SECRET}

http.client.connect-timeout-ms=5000
http.client.read-timeout-ms=10000

management.endpoints.web.exposure.include=health,info,metrics,prometheus

server.port=${SERVER_PORT:8085}
server.servlet.context-path=/api
server.forward-headers-strategy=framework

logging.level.org.springframework.kafka=WARN
logging.level.ar.edu.uade.analytics.kafka=WARN
logging.level.ar.edu.uade.analytics.messaging=WARN
logging.level.org.hibernate.SQL=WARN
logging.level.org.hibernate.orm.jdbc.bind=WARN


### INICIO SOLUCIÓN ###
# 1. Configurar el Deserializador de Valor para JSON
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
### FIN SOLUCIÓN ###

### INICIO SOLUCIÓN ###
# 2. Indicar al JsonDeserializer que ignore los headers de tipo (TypeId)
spring.kafka.consumer.properties.spring.json.use.type.headers=false
# 3. Especificar la clase por defecto a la que debe deserializar.
spring.kafka.consumer.properties.spring.json.value.default.type=ar.edu.uade.analytics.kafka.EventMessage
# 4. (Recomendado) Confiar en todos los paquetes al deserializar.
spring.kafka.consumer.properties.spring.json.trusted.packages=*
### FIN SOLUCIÓN ###
